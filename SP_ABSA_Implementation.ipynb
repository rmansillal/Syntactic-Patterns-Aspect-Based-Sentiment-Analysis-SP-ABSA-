{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmansillal/Syntactic-Patterns-Aspect-Based-Sentiment-Analysis-SP-ABSA-/blob/main/SP_ABSA_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Syntactic Pattern Aspect-Based Sentiment Analysis (SP-ABSA)\n",
        "## A Reproducible Implementation for Customer Feedback Analysis\n",
        "\n",
        "This notebook provides a complete implementation of the SP-ABSA methodology. It uses spaCy for linguistic analysis and a Hugging Face Transformer model for context-aware sentiment classification.\n",
        "\n",
        "Methodology Overview:\n",
        "\n",
        "   * Syntactic Parsing: A sentence is parsed to identify grammatical relationships between words.\n",
        "\n",
        "   * Pattern Matching: The parsed sentence is scanned for four predefined syntactic patterns that commonly express opinions.\n",
        "\n",
        "   * Triplet Extraction: For each matched pattern, an (Aspect, Attribute, Sentiment) triplet is extracted.\n",
        "\n",
        "   * Sentiment Analysis: A two-stage sentiment analysis is performed to determine the polarity for each extracted attribute."
      ],
      "metadata": {
        "id": "uMpzYZYuxMcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Section 1: Setup and Initialization\n",
        "# ==============================================================================\n",
        "# All imports and model initializations are consolidated here for clarity.\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.tokens import Token\n",
        "from transformers import pipeline, logging as hf_logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import re\n",
        "import ast\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import List, Tuple, Callable, Dict, Any, Set\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "import math\n",
        "\n",
        "# --- Initialize Models and Tools ---\n",
        "\n",
        "# Suppress verbose informational messages from the Hugging Face transformers library.\n",
        "hf_logging.set_verbosity_error()\n",
        "\n",
        "# Load the spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_lg\")\n",
        "    print(\"spaCy model 'en_core_web_lg' loaded successfully.\")\n",
        "except OSError:\n",
        "    print(\"Downloading 'en_core_web_lg' model...\")\n",
        "    spacy.cli.download(\"en_core_web_lg\")\n",
        "    nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Initialize the VADER sentiment analyzer\n",
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "except LookupError:\n",
        "    print(\"Downloading VADER lexicon for the first time...\")\n",
        "    nltk.download('vader_lexicon', quiet=True)\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "print(\"VADER sentiment analyzer loaded successfully.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Section 2: Helper Functions\n",
        "# ==============================================================================\n",
        "# Consolidated helper functions for text cleaning, sentiment analysis, etc.\n",
        "\n",
        "def _clean_text(text: str) -> str:\n",
        "    \"\"\"Encapsulates all text cleaning operations.\"\"\"\n",
        "    cleaned_text = str(text).lower()\n",
        "    cleaned_text = re.sub(r'http\\S+|www\\S+|@\\w+|#\\w+', '', cleaned_text)\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
        "    return cleaned_text\n",
        "\n",
        "def _is_negated(token: Token) -> bool:\n",
        "    \"\"\"Robustly checks if a token is negated by checking its children or its head's children.\"\"\"\n",
        "    if any(c.dep_ == 'neg' for c in token.children):\n",
        "        return True\n",
        "    if any(c.dep_ == 'neg' for c in token.head.children):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def _get_vader_sentiment_with_score(attribute_text: str, full_context: str, is_negated: bool) -> Tuple[str, float]:\n",
        "    \"\"\"\n",
        "    Performs a two-stage, lexicon-based sentiment analysis using VADER.\n",
        "    Stage 1: Analyzes the attribute word/phrase, including explicit negation.\n",
        "    Stage 2: If the attribute is neutral, the full sentence context is used to disambiguate.\n",
        "    \"\"\"\n",
        "    text_to_analyze = f\"not {attribute_text}\" if is_negated else attribute_text\n",
        "    attr_scores = vader_analyzer.polarity_scores(text_to_analyze)\n",
        "    compound_score = attr_scores['compound']\n",
        "\n",
        "    # Stage 2: Use context for disambiguation if the attribute is neutral\n",
        "    if -0.05 < compound_score < 0.05:\n",
        "        context_scores = vader_analyzer.polarity_scores(full_context)\n",
        "        if abs(context_scores['compound']) > abs(compound_score):\n",
        "            compound_score = context_scores['compound']\n",
        "\n",
        "    if compound_score >= 0.05:\n",
        "        final_label = 'positive'\n",
        "    elif compound_score <= -0.05:\n",
        "        final_label = 'negative'\n",
        "    else:\n",
        "        final_label = 'neutral'\n",
        "    return final_label, compound_score\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Section 3: Data Loading & Unsupervised Lexicon Creation\n",
        "# ==============================================================================\n",
        "# CONSOLIDATED: Using a single, robust data parser.\n",
        "\n",
        "def parse_triplet_dataset(filepath: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Parses the .txt file with triplet annotations, reconstructing phrases from word indices.\n",
        "    This is the consolidated and robust version.\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    sentiment_map = {'POS': 'positive', 'NEG': 'negative', 'NEU': 'neutral'}\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            for line_num, line in enumerate(f, 1):\n",
        "                if '####' not in line:\n",
        "                    continue\n",
        "                text_part, label_part = line.strip().split('####')\n",
        "                tokens = text_part.split()\n",
        "                try:\n",
        "                    labels = ast.literal_eval(label_part)\n",
        "                    reconstructed_truths = []\n",
        "                    for label_tuple in labels:\n",
        "                        if len(label_tuple) != 3:\n",
        "                            continue\n",
        "                        aspect_indices, opinion_indices, sentiment_str = label_tuple\n",
        "                        aspect_words = [tokens[i] for i in sorted(aspect_indices) if i < len(tokens)]\n",
        "                        opinion_words = [tokens[i] for i in sorted(opinion_indices) if i < len(tokens)]\n",
        "                        if aspect_words and opinion_words:\n",
        "                            aspect_text = \" \".join(aspect_words).lower()\n",
        "                            attribute_text = \" \".join(opinion_words).lower()\n",
        "                            standard_sentiment = sentiment_map.get(sentiment_str, 'neutral')\n",
        "                            reconstructed_truths.append((aspect_text, attribute_text, standard_sentiment))\n",
        "                    if reconstructed_truths:\n",
        "                        dataset.append({'sentence': text_part, 'ground_truths': reconstructed_truths})\n",
        "                except (ValueError, SyntaxError, IndexError):\n",
        "                    print(f\"Warning: Could not parse labels on line {line_num}. Skipping.\")\n",
        "                    continue\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filepath}' was not found.\")\n",
        "        return []\n",
        "    return dataset\n",
        "\n",
        "def create_aspect_lexicon_from_text(sentences: List[str], similarity_threshold: float = 0.85) -> Dict[str, List[str]]:\n",
        "    \"\"\"Unsupervisedly extracts noun chunks, clusters them, and builds an aspect lexicon.\"\"\"\n",
        "    print(\"\\nBuilding aspect lexicon from raw sentences (unsupervised)...\")\n",
        "    candidate_aspects = []\n",
        "    stop_words = nlp.Defaults.stop_words\n",
        "    generic_terms = {'product', 'thing', 'stuff', 'item', 'lot', 'part', 'bit', 'way'}\n",
        "\n",
        "    docs = nlp.pipe(sentences, n_process=-1)\n",
        "    for doc in tqdm(docs, total=len(sentences), desc=\"1/3 Extracting Noun Chunks\"):\n",
        "        for chunk in doc.noun_chunks:\n",
        "            core_tokens = [tok for tok in chunk if tok.pos_ in {'NOUN', 'PROPN'}]\n",
        "            if core_tokens:\n",
        "                core_aspect = \" \".join(tok.text for tok in core_tokens).lower()\n",
        "                if core_aspect not in stop_words and core_aspect not in generic_terms:\n",
        "                    candidate_aspects.append(core_aspect)\n",
        "\n",
        "    if not candidate_aspects:\n",
        "        return {}\n",
        "\n",
        "    aspect_counts = Counter(candidate_aspects)\n",
        "    unique_aspects = sorted(aspect_counts.keys(), key=lambda x: aspect_counts[x], reverse=True)\n",
        "    aspect_docs = {text: nlp(text) for text in unique_aspects}\n",
        "\n",
        "    clusters, processed_aspects = [], set()\n",
        "    for aspect in tqdm(unique_aspects, desc=\"2/3 Clustering Terms\"):\n",
        "        if aspect in processed_aspects:\n",
        "            continue\n",
        "        current_cluster = {aspect}\n",
        "        doc1 = aspect_docs[aspect]\n",
        "        for other_aspect in unique_aspects:\n",
        "            if other_aspect in processed_aspects or other_aspect == aspect:\n",
        "                continue\n",
        "            doc2 = aspect_docs[other_aspect]\n",
        "            is_similar = (doc1.vector_norm and doc2.vector_norm and doc1.similarity(doc2) > similarity_threshold)\n",
        "            is_substring = (len(aspect.split()) > 1 or len(other_aspect.split()) > 1) and \\\n",
        "                           (aspect in other_aspect or other_aspect in aspect)\n",
        "            if is_similar or is_substring:\n",
        "                current_cluster.add(other_aspect)\n",
        "\n",
        "        processed_aspects.update(current_cluster)\n",
        "        clusters.append(list(current_cluster))\n",
        "\n",
        "    aspect_lexicon = {}\n",
        "    print(\"3/3 Finalizing Lexicon...\")\n",
        "    for cluster in clusters:\n",
        "        canonical_key = max(cluster, key=lambda x: aspect_counts.get(x, 0))\n",
        "        aspect_lexicon[canonical_key] = sorted(list(set(cluster)))\n",
        "\n",
        "    print(f\"Unsupervised lexicon created with {len(aspect_lexicon)} canonical aspect terms.\")\n",
        "    return aspect_lexicon\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Section 4: Unified High-Precision Pattern Checkers\n",
        "# ==============================================================================\n",
        "# REFACTORED: The logic from V1 has been formalized into these reusable checkers.\n",
        "\n",
        "PatternChecker = Callable[[Token, Token], bool]\n",
        "\n",
        "# --- Core Verb-Centric Patterns ---\n",
        "def check_nva_acomp(aspect: Token, attr: Token) -> bool:\n",
        "    \"\"\"Checks for Noun-Verb-Adjective (e.g., \"The [screen] is [great]\").\"\"\"\n",
        "    return (attr.dep_ == 'acomp' and\n",
        "            attr.head.pos_ in [\"VERB\", \"AUX\"] and\n",
        "            aspect.head == attr.head and\n",
        "            aspect.dep_ in [\"nsubj\", \"nsubjpass\"])\n",
        "\n",
        "def check_van_amod(aspect: Token, attr: Token) -> bool:\n",
        "    \"\"\"Checks for Verb-Adjective-Noun (e.g., \"It is a [great] [screen]\").\"\"\"\n",
        "    return (aspect.dep_ in [\"attr\", \"pobj\", \"dobj\"] and\n",
        "            attr.dep_ == 'amod' and\n",
        "            attr.head == aspect)\n",
        "\n",
        "def check_conjoined_attribute(aspect: Token, attr: Token) -> bool:\n",
        "    \"\"\"Checks for conjoined attributes (e.g., \"screen is bright and [clear]\").\"\"\"\n",
        "    if attr.dep_ != 'conj':\n",
        "        return False\n",
        "    first_attribute = attr.head\n",
        "    if first_attribute.head.pos_ not in [\"VERB\", \"AUX\"]:\n",
        "        return False\n",
        "    verb_token = first_attribute.head\n",
        "    return (aspect.dep_ in ['nsubj', 'nsubjpass'] and aspect.head == verb_token)\n",
        "\n",
        "# --- Core Verbless Patterns ---\n",
        "def check_verbless_an_na(aspect: Token, attr: Token) -> bool:\n",
        "    \"\"\"Checks for verbless Noun-Adjective fragments (e.g., \"[Great] [screen].\").\"\"\"\n",
        "    return (attr.dep_ == 'amod' and\n",
        "            attr.head == aspect and\n",
        "            aspect.sent.root.pos_ in [\"NOUN\", \"PROPN\"])\n",
        "\n",
        "# --- Master List of Pattern Checkers ---\n",
        "PATTERN_CHECKERS: List[Tuple[str, PatternChecker]] = [\n",
        "    (\"NVA/AVN (acomp)\", check_nva_acomp),\n",
        "    (\"VAN (amod)\", check_van_amod),\n",
        "    (\"Conjoined_Attribute\", check_conjoined_attribute),\n",
        "    (\"NA/AN (verbless)\", check_verbless_an_na),\n",
        "]\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Section 5: Core SP-ABSA Logic (Final Version)\n",
        "# ==============================================================================\n",
        "# REMOVED: sp_absa_analysis_with_scores_v1.\n",
        "# This is the final, lexicon-driven model which is more accurate and robust.\n",
        "\n",
        "def sp_absa_analysis_with_lexicon_v4(text: str, aspect_lexicon: Dict[str, List[str]]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Main orchestrator function for SP-ABSA, using a pre-built aspect lexicon.\n",
        "    This version is corrected to handle spaCy Matcher indexing robustly.\n",
        "    \"\"\"\n",
        "    cleaned_text = _clean_text(text)\n",
        "    if pd.isna(cleaned_text) or not cleaned_text or not aspect_lexicon:\n",
        "        return []\n",
        "\n",
        "    matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
        "    patterns = [nlp.make_doc(term) for terms_list in aspect_lexicon.values() for term in terms_list]\n",
        "    if not patterns:\n",
        "        return []\n",
        "    matcher.add(\"AspectTerms\", patterns)\n",
        "\n",
        "    all_triplets = []\n",
        "    doc = nlp(cleaned_text)\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    processed_pairs: Set[Tuple[int, int]] = set()\n",
        "\n",
        "    for sent in doc.sents:\n",
        "        # Filter matches to only those within the current sentence's span\n",
        "        spans_in_sent = [doc[start:end] for match_id, start, end in matches if start >= sent.start and end <= sent.end]\n",
        "        if not spans_in_sent:\n",
        "            continue\n",
        "\n",
        "        candidate_attributes = [tok for tok in sent if tok.pos_ in {\"ADJ\", \"ADV\", \"VERB\", \"NOUN\"}]\n",
        "\n",
        "        for aspect_span in spans_in_sent:\n",
        "            aspect_root = aspect_span.root\n",
        "            for attr in candidate_attributes:\n",
        "                if aspect_root.i == attr.i or (aspect_root.i, attr.i) in processed_pairs:\n",
        "                    continue\n",
        "\n",
        "                for pattern_name, checker_func in PATTERN_CHECKERS:\n",
        "                    if checker_func(aspect_root, attr):\n",
        "                        negated = _is_negated(attr)\n",
        "                        label, score = _get_vader_sentiment_with_score(attr.text, sent.text, negated)\n",
        "\n",
        "                        # Avoid neutral opinions unless they are negated\n",
        "                        if label == 'neutral' and not negated:\n",
        "                            continue\n",
        "\n",
        "                        all_triplets.append({\n",
        "                            \"aspect\": aspect_span.text.lower(),\n",
        "                            \"attribute\": attr.text.lower(),\n",
        "                            \"sentiment\": label,\n",
        "                            \"score\": score,\n",
        "                            \"pattern\": pattern_name,\n",
        "                            \"negated\": negated\n",
        "                        })\n",
        "                        processed_pairs.add((aspect_root.i, attr.i))\n",
        "                        break # Move to the next attribute after finding a pattern\n",
        "\n",
        "    # De-duplicate results\n",
        "    unique_triplets = []\n",
        "    seen_keys = set()\n",
        "    for triplet in all_triplets:\n",
        "        key = (triplet['aspect'], triplet['attribute'], triplet['sentiment'])\n",
        "        if key not in seen_keys:\n",
        "            unique_triplets.append(triplet)\n",
        "            seen_keys.add(key)\n",
        "\n",
        "    return unique_triplets\n",
        "\n",
        "def _get_full_aspect_phrase(token):\n",
        "    \"\"\"\n",
        "    Expands a noun token to its full compound phrase (e.g., 'battery life').\n",
        "    \"\"\"\n",
        "    parts = [child for child in token.children if child.dep_ == \"compound\" and child.i < token.i]\n",
        "    parts.append(token)\n",
        "    parts.sort(key=lambda t: t.i)\n",
        "    return \" \".join([p.text for p in parts]).lower()\n",
        "\n",
        "\n",
        "# Baseline model for comparison\n",
        "def dep_rule_baseline_analysis(text):\n",
        "    \"\"\"\n",
        "    A simpler, classic dependency-based rule system.\n",
        "    It looks for two common patterns:\n",
        "    1. Subject -> is -> Adjective (nsubj -> an_aux -> acomp)\n",
        "    2. Adjective -> Noun (amod)\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return []\n",
        "\n",
        "    doc = nlp(str(text).lower())\n",
        "    triplets = []\n",
        "\n",
        "    for token in doc:\n",
        "        # Pattern 1: Subject is Adjective (e.g., \"screen is bright\")\n",
        "        if token.dep_ == 'acomp' and token.head.pos_ == 'AUX':\n",
        "            subjects = [child for child in token.head.children if child.dep_ == 'nsubj']\n",
        "            if subjects:\n",
        "                aspect = _get_full_aspect_phrase(subjects[0])\n",
        "                attribute = token.text\n",
        "                sentiment_scores = vader_analyzer.polarity_scores(attribute)\n",
        "\n",
        "                if sentiment_scores['compound'] > 0.05:\n",
        "                    sentiment = 'positive'\n",
        "                elif sentiment_scores['compound'] < -0.05:\n",
        "                    sentiment = 'negative'\n",
        "                else:\n",
        "                    sentiment = 'neutral'\n",
        "\n",
        "                triplets.append({'aspect': aspect, 'attribute': attribute, 'sentiment': sentiment})\n",
        "\n",
        "        # Pattern 2: Adjectival modifier (e.g., \"a good screen\")\n",
        "        if token.dep_ == 'amod':\n",
        "            aspect = _get_full_aspect_phrase(token.head)\n",
        "            attribute = token.text\n",
        "            sentiment_scores = vader_analyzer.polarity_scores(attribute)\n",
        "\n",
        "            if sentiment_scores['compound'] > 0.05:\n",
        "                sentiment = 'positive'\n",
        "            elif sentiment_scores['compound'] < -0.05:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "\n",
        "            triplets.append({'aspect': aspect, 'attribute': attribute, 'sentiment': sentiment})\n",
        "\n",
        "    return triplets\n",
        "# def dep_rule_baseline_analysis(text: str) -> list:\n",
        "#     \"\"\"A simpler, classic dependency-based rule system for baseline comparison.\"\"\"\n",
        "#     if pd.isna(text):\n",
        "#         return []\n",
        "#     doc = nlp(str(text).lower())\n",
        "#     triplets = []\n",
        "#     for token in doc:\n",
        "#         # Pattern 1: Subject is Adjective\n",
        "#         if token.dep_ == 'acomp' and token.head.pos_ == 'AUX':\n",
        "#             subjects = [child for child in token.head.children if child.dep_ == 'nsubj']\n",
        "#             if subjects:\n",
        "#                 label, _ = _get_vader_sentiment_with_score(token.text, token.sent.text, _is_negated(token))\n",
        "#                 triplets.append({'aspect': subjects[0].text, 'attribute': token.text, 'sentiment': label})\n",
        "#         # Pattern 2: Adjectival modifier\n",
        "#         if token.dep_ == 'amod':\n",
        "#             label, _ = _get_vader_sentiment_with_score(token.text, token.sent.text, _is_negated(token))\n",
        "#             triplets.append({'aspect': token.head.text, 'attribute': token.text, 'sentiment': label})\n",
        "#     return triplets\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Section 6: Evaluation Pipeline\n",
        "# ==============================================================================\n",
        "# REFACTORED: Using the improved evaluation logic with partial matching.\n",
        "# The old run_full_evaluation is removed.\n",
        "\n",
        "def evaluate_with_partial_matching(predicted_triplets: set, true_triplets: set) -> dict:\n",
        "    \"\"\"\n",
        "    Evaluates triplets with partial matching for aspect/attribute and exact for sentiment.\n",
        "    Returns counts for TP, FP, FN.\n",
        "    \"\"\"\n",
        "    matched_true_indices = [False] * len(true_triplets)\n",
        "    tp, fp = 0, 0\n",
        "\n",
        "    pred_list = list(predicted_triplets)\n",
        "    true_list = list(true_triplets)\n",
        "\n",
        "    for pred_aspect, pred_attr, pred_sent in pred_list:\n",
        "        is_match_found = False\n",
        "        for j, (true_aspect, true_attr, true_sent) in enumerate(true_list):\n",
        "            if matched_true_indices[j]:\n",
        "                continue\n",
        "\n",
        "            # Partial match for aspect/attribute, exact for sentiment\n",
        "            if (pred_aspect in true_aspect or true_aspect in pred_aspect) and \\\n",
        "               (pred_attr in true_attr or true_attr in true_attr) and \\\n",
        "               (pred_sent == true_sent):\n",
        "                matched_true_indices[j] = True\n",
        "                is_match_found = True\n",
        "                break\n",
        "\n",
        "        if is_match_found:\n",
        "            tp += 1\n",
        "        else:\n",
        "            fp += 1\n",
        "\n",
        "    fn = matched_true_indices.count(False)\n",
        "    return {\"tp\": tp, \"fp\": fp, \"fn\": fn}\n",
        "\n",
        "def evaluate_model(model_func: Callable, evaluation_data: list, model_name: str, aspect_lexicon: dict = None) -> dict:\n",
        "    \"\"\"Unified model evaluation function.\"\"\"\n",
        "    total_tp, total_fp, total_fn = 0, 0, 0\n",
        "\n",
        "    for item in tqdm(evaluation_data, desc=f\"Evaluating {model_name}\"):\n",
        "        true_triplets = set(item['ground_truths'])\n",
        "\n",
        "        # Handle function arguments for different models\n",
        "        if \"V4\" in model_name:\n",
        "            predictions_raw = model_func(item['sentence'], aspect_lexicon=aspect_lexicon)\n",
        "        else: # Baseline\n",
        "            predictions_raw = model_func(item['sentence'])\n",
        "\n",
        "        predicted_triplets = {(p['aspect'], p['attribute'], p['sentiment']) for p in predictions_raw}\n",
        "\n",
        "        eval_results = evaluate_with_partial_matching(predicted_triplets, true_triplets)\n",
        "        total_tp += eval_results['tp']\n",
        "        total_fp += eval_results['fp']\n",
        "        total_fn += eval_results['fn']\n",
        "\n",
        "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"model_name\": model_name, \"tp\": total_tp, \"fp\": total_fp, \"fn\": total_fn,\n",
        "        \"precision\": precision, \"recall\": recall, \"f1_score\": f1\n",
        "    }\n",
        "\n",
        "def display_results(results: list, num_reviews: int):\n",
        "    \"\"\"Formats and prints the evaluation results in a clean table.\"\"\"\n",
        "    report_data = [{\n",
        "        'Model': res['model_name'],\n",
        "        'TP': res['tp'], 'FP': res['fp'], 'FN': res['fn'],\n",
        "        'Precision': f\"{res['precision']:.3f}\",\n",
        "        'Recall': f\"{res['recall']:.3f}\",\n",
        "        'F1-Score': f\"{res['f1_score']:.3f}\"\n",
        "    } for res in results]\n",
        "\n",
        "    df_results = pd.DataFrame(report_data)\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"--- Quantitative Results on Triplet Extraction ---\".center(100))\n",
        "    print(\"--- (Partial Matching for Aspect/Attribute + Exact Match for Sentiment) ---\".center(100))\n",
        "    print(\"=\"*100)\n",
        "    print(df_results.to_string(index=False))\n",
        "    print(f\"\\n*Evaluation based on {num_reviews} reviews.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Section 7: Visualizations\n",
        "# ==============================================================================\n",
        "# CONSOLIDATED: Keeping the enhanced and more functional versions of the plots.\n",
        "\n",
        "def visualize_priority_matrix(df: pd.DataFrame, top_x: int = None, label_threshold: int = 5):\n",
        "    \"\"\"\n",
        "    Creates an enhanced 2x2 matrix plotting aspects by mention frequency vs. average\n",
        "    sentiment, with conditional labeling to prevent overlap.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        print(\"The DataFrame is empty. Cannot generate a plot.\")\n",
        "        return\n",
        "\n",
        "    aspect_summary = df.groupby('aspect').agg(\n",
        "        volume=('sentiment', 'count'),\n",
        "        avg_sentiment=('score', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    if top_x and isinstance(top_x, int) and top_x > 0:\n",
        "        aspect_summary = aspect_summary.nlargest(top_x, 'volume')\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, ax = plt.subplots(figsize=(14, 9))\n",
        "\n",
        "    scatter = ax.scatter(\n",
        "        aspect_summary['avg_sentiment'], aspect_summary['volume'],\n",
        "        s=aspect_summary['volume'] * 80,\n",
        "        c=aspect_summary['avg_sentiment'],\n",
        "        cmap='RdYlGn', edgecolor='black', alpha=0.7, zorder=10\n",
        "    )\n",
        "\n",
        "    for i, row in aspect_summary.iterrows():\n",
        "        if row['volume'] >= label_threshold:\n",
        "            offset = (row['volume']**0.5) * 0.05\n",
        "            ax.text(row['avg_sentiment'], row['volume'] + offset, row['aspect'],\n",
        "                    ha='center', va='bottom', fontsize=10, weight='bold', zorder=11)\n",
        "\n",
        "    xmin, xmax = ax.get_xlim()\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    ax.text(xmax, ymax, \"PRAISE & PROMOTE\", ha='right', va='top', fontsize=12, weight='bold', alpha=0.8)\n",
        "    ax.text(xmin, ymax, \"URGENT ACTION\", ha='left', va='top', fontsize=12, weight='bold', alpha=0.8)\n",
        "    ax.text(xmax, ymin, \"LEVERAGE\", ha='right', va='bottom', fontsize=12, weight='bold', alpha=0.8)\n",
        "    ax.text(xmin, ymin, \"MONITOR\", ha='left', va='bottom', fontsize=12, weight='bold', alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Average Sentiment Score (Negative â†” Positive)', fontsize=14)\n",
        "    ax.set_ylabel('Mention Volume (Frequency)', fontsize=14)\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Average Sentiment Score')\n",
        "    plt.title(f'Aspect Priority Matrix (Top {top_x} Aspects)' if top_x else 'Aspect Priority Matrix (All Aspects)', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "def visualize_aspect_attributes(df: pd.DataFrame, top_x: int = 4):\n",
        "    \"\"\"Creates a dynamic grid of cellular graphs for the top X major aspects.\"\"\"\n",
        "    if df.empty or top_x == 0:\n",
        "        print(\"No aspects to display.\")\n",
        "        return\n",
        "\n",
        "    grouped = df.groupby(['aspect', 'attribute']).agg(\n",
        "        frequency=('sentiment', 'count'),\n",
        "        avg_score=('score', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    all_aspects = df['aspect'].value_counts()\n",
        "    num_to_display = min(top_x, len(all_aspects))\n",
        "    top_aspects = all_aspects.nlargest(num_to_display).index\n",
        "\n",
        "    ncols = math.ceil(math.sqrt(num_to_display))\n",
        "    nrows = math.ceil(num_to_display / ncols)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 7, nrows * 6))\n",
        "    axes = np.array(axes).flatten()\n",
        "\n",
        "    cmap = plt.get_cmap('RdYlGn')\n",
        "    norm = plt.Normalize(vmin=-1.0, vmax=1.0)\n",
        "\n",
        "    for i, aspect in enumerate(top_aspects):\n",
        "        ax = axes[i]\n",
        "        aspect_data = grouped[grouped['aspect'] == aspect]\n",
        "\n",
        "        G = nx.Graph()\n",
        "        G.add_node(aspect, size=3500, type='aspect')\n",
        "\n",
        "        for _, row in aspect_data.iterrows():\n",
        "            attr, freq = row['attribute'], row['frequency']\n",
        "            G.add_node(attr, size=1500 + freq * 200, type='attribute')\n",
        "            G.add_edge(aspect, attr, weight=freq)\n",
        "\n",
        "        pos = nx.spring_layout(G, seed=42, k=0.9)\n",
        "        node_sizes = [d['size'] for n, d in G.nodes(data=True)]\n",
        "\n",
        "        attribute_scores = aspect_data.set_index('attribute')['avg_score'].to_dict()\n",
        "        node_colors = ['skyblue' if data['type'] == 'aspect' else cmap(norm(attribute_scores.get(node, 0.0)))\n",
        "                       for node, data in G.nodes(data=True)]\n",
        "\n",
        "        nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, ax=ax)\n",
        "        nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5, ax=ax)\n",
        "\n",
        "        custom_labels = {node: node.upper() if data['type'] == 'aspect' else f\"{node}\\n({attribute_scores.get(node, 0.0):+.2f})\"\n",
        "                         for node, data in G.nodes(data=True)}\n",
        "        nx.draw_networkx_labels(G, pos, labels=custom_labels, font_size=10, ax=ax)\n",
        "\n",
        "        ax.set_title(f\"Analysis for: '{aspect.upper()}'\", fontsize=14)\n",
        "        ax.margins(0.1)\n",
        "\n",
        "    for i in range(len(top_aspects), len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "\n",
        "    plt.suptitle(f\"Aspect-Attribute Insight Graphs (Top {num_to_display} Aspects)\", fontsize=20)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# Section 8: Main Execution Block\n",
        "# ==============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the entire pipeline.\"\"\"\n",
        "    FILE_PATH = 'train_triplets.txt'\n",
        "\n",
        "    # 1. Load Ground Truth Data\n",
        "    sentences_and_truths = parse_triplet_dataset(FILE_PATH)\n",
        "    if not sentences_and_truths:\n",
        "        print(\"\\nExecution stopped: Could not load ground truth data.\")\n",
        "        return\n",
        "    print(f\"\\nSuccessfully parsed {len(sentences_and_truths)} sentences with triplet annotations.\")\n",
        "\n",
        "    all_sentences = [item['sentence'] for item in sentences_and_truths]\n",
        "\n",
        "    # 2. Create Aspect Lexicon Unsupervisedly\n",
        "    ASPECT_LEXICON = create_aspect_lexicon_from_text(all_sentences)\n",
        "\n",
        "    # 3. Evaluate Models\n",
        "    models_to_evaluate = {\n",
        "        \"SP-ABSA V4 (Lexicon-driven)\": sp_absa_analysis_with_lexicon_v4,\n",
        "        \"Dep-Rule Baseline\": dep_rule_baseline_analysis\n",
        "    }\n",
        "\n",
        "    all_results = []\n",
        "    for name, func in models_to_evaluate.items():\n",
        "        result = evaluate_model(func, sentences_and_truths, name, aspect_lexicon=ASPECT_LEXICON)\n",
        "        all_results.append(result)\n",
        "\n",
        "    display_results(all_results, len(sentences_and_truths))\n",
        "\n",
        "    # 4. Run Analysis and Visualization on the best model\n",
        "    print(\"\\nAnalyzing full dataset with the final model (SP-ABSA V4)...\")\n",
        "    all_triplets_v4 = []\n",
        "    for sentence in tqdm(all_sentences, desc=\"Processing Reviews with V4 Model\"):\n",
        "        triplets = sp_absa_analysis_with_lexicon_v4(sentence, ASPECT_LEXICON)\n",
        "        all_triplets_v4.extend(triplets)\n",
        "\n",
        "    df_v4 = pd.DataFrame(all_triplets_v4)\n",
        "    print(\"Analysis complete. DataFrame for V4 model created.\")\n",
        "\n",
        "    # 5. Generate Visualizations\n",
        "    if not df_v4.empty:\n",
        "        visualize_priority_matrix(df_v4)#, top_x=20)\n",
        "        visualize_aspect_attributes(df_v4)#, top_x=4)\n",
        "    else:\n",
        "        print(\"\\nNo triplets were extracted by the V4 model, skipping visualization.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "EAZse5J5E3tZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}